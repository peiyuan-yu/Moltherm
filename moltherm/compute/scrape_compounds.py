# coding: utf-8

import os
import requests
import re
from bs4 import BeautifulSoup

import pubchempy as pcp

from pymongo.errors import DuplicateKeyError

from pymatgen.io.babel import BabelMolAdaptor

from atomate.qchem.database import QChemCalcDb

__author__ = "Evan Spotte-Smith"
__version__ = "0.2"
__maintainer__ = "Evan Spotte-Smith"
__email__ = "espottesmith@gmail.com"
__status__ = "Beta"
__date__ = "June 2018"


class ReaxysParser:
    """
    Parser for reaction data from the Reaxys reaction database. This class can
    extract important reaction metadata from an exported XML file, restore that
    pertinent information, including molecule structure files (*.mol), and
    interact with a database for additional storage.
    """

    def __init__(self, base_dir):
        """
        ReaxysScraper

        :param base_dir: Base directory for parsing and generating data.
        """

        self.base_dir = base_dir

    def parse_reaxys_xml(self, filename):
        """
        Parses an XML file generated by the Reaxys API.

        :param filename: str referring to XML file from Reaxys.
        :return: List of dicts including reactant CTAB, product CTAB, and
        metadata.
        """

        results = []

        filepath = os.path.join(self.base_dir, filename)

        with open(filepath, 'r') as fileobj:
            xml = fileobj.read()
            parsed = BeautifulSoup(xml, "lxml-xml")

            reactions = parsed.find_all("reaction")

            for reaction in reactions:
                # Screen for reactions with more than two reactants
                # or more than one product
                pros = reaction.find_all("RY.PRO")
                rcts = reaction.find_all("RY.RCT")
                if not ((len(pros) == 1 and len(rcts) == 2) or (len(pros) == 2 and len(rcts) == 1)):
                    continue

                # Generate metadata from reaction header information
                # Will be passed along with CTAB information
                index = int(reaction["index"])
                rxn_id = int(reaction.find("RX.ID").text)
                solvents = set([sol.text for sol
                                in reaction.find_all("RXD.SOL")])

                rct_ids = reaction.find_all("RX.RXRN")
                rct_names = reaction.find_all("RX.RCT")
                rct_meta = [(int(e.text), rct_names[i].text) for i, e
                            in enumerate(rct_ids)]

                pro_ids = reaction.find_all("RX.PXRN")
                pro_names = reaction.find_all("RX.PRO")
                pro_meta = [(int(e.text), pro_names[i].text) for i, e
                            in enumerate(pro_ids)]

                meta = {"index": index,
                        "rxn_id": rxn_id,
                        "solvents": solvents,
                        "rct_meta": sorted(rct_meta, key=lambda x: x[0]),
                        "pro_meta": sorted(pro_meta, key=lambda x: x[0])}

                # Capture reactant CTAB information
                # Make sure that ordering is the same for metadata and CTAB
                rcts = sorted(reaction.find_all("RY.RCT"),
                              key=lambda x: int(x["rn"]))
                rcts = [rct.text for rct in rcts]

                pros = sorted(reaction.find_all("RY.PRO"),
                              key=lambda x: int(x["rn"]))

                pros = [pro.text for pro in pros]

                rxn = {"rcts": rcts, "pros": pros, "meta": meta}

                try:
                    pro_atoms = []
                    for pro in rxn["pros"]:
                        ad = BabelMolAdaptor.from_string(pro, file_format="mol")
                        ad.add_hydrogen()
                        for site in ad.pymatgen_mol:
                            pro_atoms.append(str(site.specie))

                    rct_atoms = []
                    for rct in rxn["rcts"]:
                        ad = BabelMolAdaptor.from_string(rct, file_format="mol")
                        ad.add_hydrogen()
                        for site in ad.pymatgen_mol:
                            rct_atoms.append(str(site.specie))

                    if sorted(pro_atoms) == sorted(rct_atoms):
                        results.append(rxn)
                except:
                    continue

        return results

    def get_unique_reactions(self, files):
        """
        Parses a set of Reaxys XML files and filter out duplicates.

        :param files: List of strings representing Reaxys XML files to be processed.
        :return: unique_ids (list of strings representing Reaxys ids) and unique
            (list of dicts representing unique reactions)
        """

        overall = []

        for file in files:
            res = self.parse_reaxys_xml(file)
            overall += res

        unique_ids = []
        unique = []
        for rxn in overall:
            if rxn["meta"]["rxn_id"] not in unique_ids:
                unique_ids.append(rxn["meta"]["rxn_id"])
                unique.append(rxn)

        return unique_ids, unique

    def store_reaxys_reactions_files(self, reactions, base_path=None):
        """
        Create CTAB (.mol) files and metadata XML files from parsed XML data.

        :param reactions: List of reactions, defined as above.
        :return:
        """

        for reaction in reactions:
            rxn_id = reaction["meta"]["rxn_id"]
            index = reaction["meta"]["index"]

            if base_path is None:
                path = os.path.join(self.base_dir, "reactions")
            else:
                path = os.path.join(base_path, "reactions")

            if not os.path.exists(path):
                os.makedirs(path)

            # Create metadata file
            with open(os.path.join(path, "{}.xml".format(rxn_id)), 'w') as file:
                file.write("<metadata>")
                file.write("<index>%(index)s</index>\n" % {"index": str(index)})
                file.write("<reaxysid>%(id)s</reaxysid>\n" % {"id": str(rxn_id)})

                file.write("<solvents>%(solvents)s</solvents>\n" % {"solvents": " || ".join(reaction["meta"]["solvents"])})

                for i, rct in enumerate(reaction["meta"]["rct_meta"]):
                    rct_info = {"num": str(i),
                                "name": rct[1],
                                "id": str(rct[0])
                                }
                    file.write("""<rct num=%(num)s>
<rctname>%(name)s</rctname>
<rctid>%(id)s</rctid>
</rct>\n""" % rct_info)

                for i, pro in enumerate(reaction["meta"]["pro_meta"]):
                    pro_info = {"num": str(i),
                                "name": pro[1],
                                "id": str(pro[0])}
                    file.write("""<pro num=%(num)s>
<proname>%(name)s</proname>
<proid>%(id)s</proid>
</pro>\n""" % pro_info)

                file.write("</metadata>")

            if base_path is None:
                path = os.path.join(self.base_dir, "molecules")
            else:
                path = os.path.join(base_path, "molecules")

            if not os.path.exists(path):
                os.makedirs(path)

            # Create reactant files, named with their Reaxys IDs
            reactants = reaction["meta"]["rct_meta"]
            for i, e in enumerate(reactants):
                rct_path = os.path.join(path, str(e[0]))
                if not os.path.exists(rct_path):
                    os.makedirs(rct_path)
                filename = str(e[0]) + ".mol"
                with open(os.path.join(rct_path, filename), 'w') as file:
                    file.write(reaction["rcts"][i])

            # Create product file, named with its Reaxys ID
            products = reaction["meta"]["pro_meta"]
            for i, e in enumerate(products):
                pro_path = os.path.join(path, str(e[0]))
                if not os.path.exists(pro_path):
                    os.makedirs(pro_path)
                filename = str(e[0]) + ".mol"
                with open(os.path.join(pro_path, filename), 'w') as file:
                    file.write(reaction["pros"][i])

    @staticmethod
    def store_reaxys_reactions_db(reactions, db_file="db.json",
                                  collection_name="reaxys"):
        """
        Insert reaction information into a MongoDB database.

        :param reactions: List of reactions, defined as above.
        :param db_file: A config file indicating the database into which the
        reactions will be inserted.
        :param collection_name: Collection within the database in which to store
        the reactions.
        :return: List of rxn_ids that were added to collection collection_name
        as a result of this method call
        """

        # Set up MongoDB database with pymatgen-db and pymongo
        try:
            db = QChemCalcDb.from_db_file(db_file)
        except:
            raise RuntimeError("Cannot connect to database. Please check your"
                               " configuration and try again.")

        collection = db.db[collection_name]

        just_added = []

        collection.create_index("rxn_id", unique=True)

        for reaction in reactions:
            # Reorganize for database insertion
            rxn = {}
            rxn["rxn_id"] = str(reaction["meta"]["rxn_id"])
            rxn["pro_ids"] = [str(p[0]) for p in reaction["meta"]["pro_meta"]]
            rxn["pro_names"] = [p[1] for p in reaction["meta"]["pro_meta"]]
            rxn["rct_ids"] = [str(r[0]) for r in reaction["meta"]["rct_meta"]]
            rxn["rct_names"] = [r[1] for r in reaction["meta"]["rct_meta"]]
            rxn["solvents"] = list(reaction["meta"]["solvents"])

            try:
                collection.insert_one(rxn)
                just_added.append(rxn["rxn_id"])
            except DuplicateKeyError:
                continue

        return just_added


class EPISuiteParser:
    """
    This class processes outputs from the Environmental Protection Agency's
    EPI Suite. It can also interface with a MongoDB database in order to store
    this data.

    """

    def __init__(self, db_file="db.json"):
        """
        :param db_file: Path to database config file.
        """

        self.db_file = db_file

        try:
            self.db = QChemCalcDb.from_db_file(self.db_file)
        except:
            self.db = None

    @staticmethod
    def parse_epi_suite_summary(file):
        """
        Parse predicted data from the US EPA's EPI Suite batch mode.

        Currently, this function only extracts the predicted boiling point,
        melting point, and solubility.

        :param file: Path to EPI Suite output file.
        :return: list of dicts with predicted molecular data
        """

        parsed_results = []

        with open(file, 'r', encoding="ISO-8859-1") as file:
            entries = file.read().split("\n\n========================\n\n")[0:-1]

            for entry in entries:
                smiles = re.search(r"SMILES\s+:\s+([A-Za-z0-9=\(\)#\[\]\+\-@]+\n?\s*[A-Za-z0-9=\(\)#\[\]\+\-@]*)",
                                   entry)
                if smiles:
                    smiles = smiles.group(1).replace("\n", "").replace(" ", "")
                else:
                    smiles = None

                name = re.search(r"CHEM\s+:\s+([A-Z/_a-z0-9]+)\s*", entry)
                if name:
                    mol_id = name.group(1)
                else:
                    mol_id = None

                bp = re.search(r"\s+Boiling Pt \(deg C\):\s+([0-9]+\.[0-9]+)\s+\(Adapted Stein & Brown method\)", entry)
                if bp:
                    bp = float(bp.group(1))
                else:
                    bp = None

                mp = re.search(r"\s+Melting Pt \(deg C\):\s+([0-9]+\.[0-9]+)\s+\(Mean or Weighted MP\)", entry)
                if mp:
                    mp = float(mp.group(1))
                else:
                    mp = None

                vp = re.search(r"\s+VP \(Pa, 25 deg C\)\s+:\s+([0-9]+\.[0-9]+)\s+\(Mean VP of Antoine & Grain methods\)", entry)
                if vp:
                    vp = float(vp.group(1))
                else:
                    vp = None

                solubility = re.search(r"\s+Water Solubility at 25 deg C \(mg/L\):\s+([e0-9\+\-\.]+)", entry)
                if solubility:
                    solubility = float(solubility.group(1))
                else:
                    solubility = None

                log_kow = re.search(r"\s+log Kow used:\s+([0-9]+\.[0-9]+)\s+\(estimated\)", entry)
                if log_kow:
                    log_kow = float(log_kow.group(1))
                else:
                    log_kow = None

                parsed_results.append({"mol_id": mol_id,
                                       "smiles": smiles,
                                       "bp": bp,
                                       "mp": mp,
                                       "vp": vp,
                                       "solubility": solubility,
                                       "log_kow": log_kow})
        return parsed_results

    @staticmethod
    def parse_epi_suite_complete(file):
        """
        Parse predicted data from the US EPA's EPI Suite batch mode.

        Currently, this function only extracts the predicted boiling point,
        melting point, and solubility.

        :param file: Path to EPI Suite output file.
        :return: list of dicts with predicted molecular data
        """

        parsed_results = []

        with open(file, 'r', encoding="ISO-8859-1") as file:
            entries = file.read().split("\n\n========================\n\n")[0:-1]

            for entry in entries:
                smiles = re.search(r"SMILES\s+:\s+([A-Za-z0-9=\(\)#\[\]\+\-@]+\n?\s*[A-Za-z0-9=\(\)#\[\]\+\-@]*)",
                                   entry)
                if smiles:
                    smiles = smiles.group(1).replace("\n", "").replace(" ", "")
                else:
                    smiles = None

                name = re.search(r"CHEM\s+:\s+([A-Z/_a-z0-9]+)\s*", entry)
                if name:
                    mol_id = name.group(1)
                else:
                    mol_id = None

                bp = re.search(r"\s+\(Using BP:\s+(\-?[0-9]+\.[0-9]+) deg C", entry)
                if bp:
                    bp = float(bp.group(1))
                else:
                    bp = None

                mp = re.search(r"\s+Selected MP:\s+(\-?[0-9]+\.[0-9]+) deg C", entry)
                if mp:
                    mp = float(mp.group(1))
                else:
                    mp = None

                vp = re.search(r"\s+Selected VP:\s+([Ee0-9\+\-\.]+) mm Hg", entry)
                if vp:
                    vp = float(vp.group(1)) * 133.322
                else:
                    vp = None

                solubility = re.search(r"\s+Water Sol:\s+([Ee0-9\+\-\.]+) mg/L", entry)
                if solubility:
                    solubility = float(solubility.group(1))
                else:
                    solubility = None

                log_kow = re.search(r"\s+Log Kow\s+=\s+(\-?[0-9]+\.[0-9]+)", entry)
                if log_kow:
                    log_kow = float(log_kow.group(1))
                else:
                    log_kow = None

                parsed_results.append({"mol_id": mol_id,
                                       "smiles": smiles,
                                       "bp": bp,
                                       "mp": mp,
                                       "vp": vp,
                                       "solubility": solubility,
                                       "log_kow": log_kow})
        return parsed_results

    def store_epi_suite_db(self, entries, collection="episuite"):
        """
        :param entries: List of dictionaries, with each entry representing the
        EPI Suite output data for a molecule.
        :param collection: Database collection for EPI Suite data. Default is
        "episuite".
        :return: list of mol_ids corresponding to all entries just added to
        collection.
        """

        collection = self.db.db[collection]

        collection.create_index("mol_id", unique=True)

        just_added = []

        for entry in entries:
            try:
                collection.insert_one(entry)
                just_added.append(entry["mol_id"])
            except DuplicateKeyError:
                continue

        return just_added


class PUGScraper:
    """
    Uses the PubChem Power User Gateway (PUG) REST API to
    query and identify molecules similar to a set of base molecules. In
    addition to scraping chemical ids, this class can download structure files
    and process them with pybel.

    Thank you to http://python.zirael.org/e-pubchem1.html for some inspiration
    in devising this class.
    """

    def __init__(self, cids, base_dir, sub_dirs=None):
        """
        PUGScraper
        :param cids: A dict {"category": [ids]}, where each category is a
        molecular type of interest
        :param base_dir: A string representing an absolute path where downloaded
        information (ids, SDF files) should go.
        :param sub_dirs: By default, this is None. Otherwise, it should be a
        dict {"category": "sub_dir"}, where each category in cids is
        represented, and where each sub_dir is a string to a subdirectory within
        base_dir (these will be created if they don't already exist).
        """

        self.cids = cids
        self.base_dir = base_dir
        self.sub_dirs = sub_dirs

    def create_dirs(self):
        """
        Ensures that all paths and subpaths required by PUGScraper exist.
        :return:
        """
        try:
            if not os.path.exists(self.base_dir):
                os.makedirs(self.base_dir)
            if self.sub_dirs is not None:
                for cat in self.sub_dirs.keys():
                    sub_dir = os.path.join(self.base_dir, self.sub_dirs[cat])
                    if not os.path.exists(sub_dir):
                        os.makedirs(sub_dir)
        except:
            raise ValueError("Given directory paths are invalid; check that"
                             "strings have been input correctly, and that you"
                             "have permission to use the given directories.")

    def download_files_rest(self, cids, pngs=True, download_parents=False):
        """
        Generalized function for downloading files (both SDF and PNG, for quick
        reference of structure and for full coordinate and bonding information),
        which calls either download_files_rest or download_files_pug, depending
        on if REST is being used.

        :param cids: A dict {"category": {id:[ids]}}, where each category is a
        molecular type of interest.
        :param pngs: If True, PNG files will be downloaded alongside SDF files.
        :param download_parents: If True, then files will be downloaded for
        parent molecules, in addition to the molecules returned from their
        queries.
        :return:
        """

        order = 0

        formats = ["SDF"]
        if pngs:
            formats.append("PNG")

        for cat in cids.keys():
            download_ids = []

            if self.sub_dirs is not None:
                cat_path = os.path.join(self.base_dir, self.sub_dirs[cat])
            else:
                cat_path = os.path.join(self.base_dir)

            for parent in cids[cat].keys():

                if download_parents:
                    download_ids.append(parent)

                for cid in cids[cat][parent]:
                    download_ids.append(cid)

            for format in formats:
                for cid in download_ids:
                    filename = str(cid) + "_" + str(order) + "." + format.lower()
                    filepath = os.path.join(cat_path, filename)
                    pcp.download(format, filepath, cid, overwrite=True)
                    order += 1

    def store_cids(self, cids):
        """
        Store cids in a text (.txt) file.

        By default, this stores not only the category and the cids, but also the
        CID that caused each other CID to be matched.

        :param cids: A dict {"category": {id:[ids]}}, where each category is a
        molecular type of interest.
        :return:
        """

        self.create_dirs()

        for cat in cids.keys():
            if self.sub_dirs is not None:
                filepath = os.path.join(self.base_dir, self.sub_dirs[cat],
                                        "cids.txt")
            else:
                filepath = os.path.join(self.base_dir, "cids.txt")

            with open(filepath, 'a') as cidfile:
                cidfile.write("Category: " + cat + "\n")
                for parent in cids[cat].keys():
                    cidfile.write("\t" + "Parent: " + str(parent) + "\n")
                    for cid in cids[cat][parent]:
                        cidfile.write("\t\t" + str(cid) + "\n")

    def scrape_similar_rest(self, cids, threshold=90, max_records=10000):
        """
        Searches by similarity (2D) using PUG-REST.

        :param cids:
        :param threshold:
        :param max_records:
        :return: A dict {"category": {id:[matches]}}, where each id in each
        category is stored along with its matches (which take the form of CIDs.
        """

        output = {}
        queries_run = 0

        for cat in cids.keys():
            output[cat] = {}
            for cid in cids[cat]:
                queries_run = self.check_queries(queries_run)
                result = pcp.get_cids(cid, namespace="cid",
                                           domain="compound",
                                           searchtype="similarity",
                                           threshold=threshold,
                                           max_records=max_records)
                output[cat][cid] = result

        return output

    def scrape_super_rest(self, cids, match_isotopes=False, match_charges=False,
                          match_tautomers=False,
                          rings_not_embedded=False,
                          single_double_bonds_match=True,
                          chains_match_rings=True,
                          strip_hydrogen=False,
                          stereo="ignore",
                          max_records=10000):
        """
        Generalized function for superstructure searches (searching for
        molecules that contain a given molecule within them).
        Kwargs are those used by PUG and PUG-REST for similarity queries.

        Parameter descriptions are largely taken from
        http://pubchemdocs.ncbi.nlm.nih.gov/pug-rest

        :param cids: A dict {"category": [ids]}, where each category is a
        molecular type of interest.
        :param match_isotopes: Atoms must be of the same specified isotope.
        :param match_charges: Atoms must match the specified charge.
        :param match_tautomers: Allows matching with tautomers.
        :param rings_not_embedded: Rings may not be embedded in a larger system.
        :param single_double_bonds_match: In an aromatic compound, either single
        or double bonds may match the aromatic bonds.
        :param chains_match_rings: Chain bonds in the query may match rings in hits.
        :param strip_hydrogen: Remove explicit hydrogens before searching.
        :param stereo: How to handle stereoisomers: either "ignore", "exact",
        "relative", or "nonconflicting".
        :param max_records: Maximum number of hits.
        :return: A dict {"category": {id:[matches]}}, where each id in each
        category is stored along with its matches (which take the form of CIDs.
        """

        output = {}
        queries_run = 0

        for cat in cids.keys():
            output[cat] = {}
            for cid in cids[cat]:
                queries_run = self.check_queries(queries_run)
                result = pcp.get_cids(cid, namespace="cid",
                                      domain="compound",
                                      searchtype="superstructure",
                                      match_isotopes=match_isotopes,
                                      match_charges=match_charges,
                                      match_tautomers=match_tautomers,
                                      rings_not_embedded=rings_not_embedded,
                                      single_double_bonds_match=single_double_bonds_match,
                                      chains_match_rings=chains_match_rings,
                                      strip_hydrogen=strip_hydrogen,
                                      stereo=stereo,
                                      max_records=max_records)
                output[cat][cid] = result

        return output


class ChemSpiderScraper:
    """
    Uses BeautifulSoup on ChemSpider API to extract boiling and melting
    points for chemicals of interest.
    """

    def __init__(self, base_dir, token, db_file="db.json",
                 collection_name="chemspider"):
        """
        Initialize ChemSpider Scraper.

        :param base_dir: Directory path where files should be stored.
        :param token: ChemSpider API token (str). This should be obtained from
            ChemSpider prior to use.
        :param host: For instance, "localhost" if the database is hosted on the
            home server.
        :param port: Typically, for MongoDB, this will be 27017.
        :param db_name: Name of the database to enter into.
        :param collection_name: Name of the collection to store ChemSpider into.
        :param user: Database username.
        :param password: Database password. If no password is used, an empty
            string should be passed.

        :return:
        """

        self.base_dir = base_dir

        self.base_url = "https://api.rsc.org/compounds/v1/"
        self.headers = {"apikey": token, "Content-Type": "application/json"}

        self.db_file = db_file

        try:
            self.db = QChemCalcDb.from_db_file(self.db_file)
        except:
            raise RuntimeError("Cannot connect to database. Please check your"
                               " configuration and try again")

        self.collection = self.db.db[collection_name]

    def get_chemspider_ids(self, molecules, max_attempts=100):
        """
        From list of :class: pymatgen.core.structure.Molecule, extract
        ChemSpider IDs for use in subsequent searches.

        :param molecules: List of Molecules.
        :param max_attempts: How many times should a query be checked before
            it should be given up?
        :return: dict {molecule: ids}, where ids is an list of ints.
        """

        results = {}

        for molecule in molecules:
            adaptor = BabelMolAdaptor(molecule)
            # Use Canonical SMILES to ensure uniqueness
            smiles = adaptor.pybel_mol.write("can").strip()

            init_url = self.base_url + "filter/smiles"
            data = {"smiles": str(smiles)}
            init_req = requests.post(init_url, json=data, headers=self.headers)
            try:
                query_id = init_req.json()['queryId']

                status_url = self.base_url + "filter/{}/status".format(query_id)
                for i in range(max_attempts):
                    status_request = requests.get(status_url,
                                                  headers=self.headers)

                    if status_request.json()['status'].lower() == 'complete':
                        results_url = self.base_url + \
                                      "filter/{}/results".format(query_id)

                        results_request = requests.get(results_url,
                                                       headers=self.headers)

                        results[smiles] = results_request.json().get("results",
                                                                     [])
                        break
            except:
                results[smiles] = []

        return results

    @staticmethod
    def extract_boiling_point(csids):
        """
        Scrape experimental and/or predicted boiling point information from
        ChemSpider.

        :param csids: list of ChemSpider id.
        :return: dict containing all listed boiling points
        """

        results = {}

        for csid in csids:
            results[csid] = {}

            url = """http://parts.chemspider.com/JSON.ashx?op=GetRecordsAsCompounds&csids[0]={}&serfilter=Compound[PredictedProperties|ExperimentalProperties]""".format(str(csid))
            request = requests.get(url)

            parsed = BeautifulSoup(request.text, "lxml")

            # Turn text into dict of lists of dicts
            data = eval(parsed.body.p.text)[0]

            results[csid]["pred"] = []
            for pred in data["PredictedProperties"]:
                if pred["Name"] == "Boiling Point":
                    results[csid]["pred"].append({
                        "units": pred.get("Units", None),
                        "value": pred.get("Value", None)})

            results[csid]["exp"] = []
            for exp in data["ExperimentalProperties"]:
                if exp["Name"] == "Experimental Boiling Point":
                    results[csid]["exp"].append({
                        "units": exp.get("Units", None),
                        "value": exp.get("Value", None),
                        "source": exp.get("DataSourceName", None)})

        return results

    @staticmethod
    def extract_melting_point(csids):
        """
        Scrape experimental and/or predicted boiling point information from
        ChemSpider.

        :param csids: list of ChemSpider ids.
        :return: dict containing all listed boiling points
        """

        results = {}

        for csid in csids:
            results[csid] = {}

            url = """http://parts.chemspider.com/JSON.ashx?op=GetRecordsAsCompounds&csids[0]={}&serfilter=Compound[PredictedProperties|ExperimentalProperties]""".format(str(csid))
            request = requests.get(url)

            parsed = BeautifulSoup(request.text, "lxml")

            # Turn text into dict of lists of dicts
            data = eval(parsed.body.p.text)[0]

            results[csid]["pred"] = []
            for pred in data["PredictedProperties"]:
                if pred["Name"] == "Boiling Point":
                    results[csid]["pred"].append({
                        "units": pred.get("Units"),
                        "value": pred.get("Value")})

            results[csid]["exp"] = []
            for exp in data["ExperimentalProperties"]:
                if exp["Name"] == "Experimental Melting Point":
                    results[csid]["exp"].append({
                        "units": exp.get("Units"),
                        "value": exp.get("Value"),
                        "source": exp.get("DataSourceName")})

        return results

    def store_data_file(self, molecules, filename="phase_properties.txt"):
        """
        Extracts melting and boiling point information, then stores it in a
        text file.

        :param molecules: List of pymatgen.core.structure.Molecule objects.

        :return:
        """
        filepath = os.path.join(self.base_dir, filename)

        for molecule in molecules:
            adaptor = BabelMolAdaptor(molecule)
            # Use Canonical SMILES to ensure uniqueness
            smiles = adaptor.pybel_mol.write("can").strip()

            csids = self.get_chemspider_ids([molecule])[smiles]

            boiling_points = self.extract_boiling_point(csids)
            melting_points = self.extract_melting_point(csids)

            with open(filepath, "a+") as file:
                file.write("Molecule: {}\n".format(smiles))

                for csid in csids:
                    file.write("\tChemSpider ID: {}\n".format(str(csid)))

                    file.write("\t\tBoiling Point Information:\n")
                    file.write("\t\t\tExperimental:\n")
                    for i, val in enumerate(boiling_points[csid]["exp"]):
                        file.write("\t\t\t\tEntry {}: Units {} Value {} Source {}\n".
                                   format(i, val["units"],
                                          val["value"], val["source"]))
                    file.write("\t\t\tPredicted:\n")
                    for i, val in enumerate(boiling_points[csid]["pred"]):
                        file.write("\t\t\t\tEntry {}: Units {} Value {}\n".
                                   format(i, val["units"], val["value"]))

                    file.write("\t\tMelting Point Information:\n")
                    file.write("\t\t\tExperimental:\n")
                    for i, val in enumerate(melting_points[csid]["exp"]):
                        file.write("\t\t\t\tEntry {}: Units {} Value {} Source {}\n".
                                   format(i, val["units"],
                                          val["value"], val["source"]))
                    file.write("\t\t\tPredicted:\n")
                    for i, val in enumerate(melting_points[csid]["pred"]):
                        file.write("\t\t\t\tEntry {}: Units {} Value {}\n".
                                   format(i, val["units"], val["value"]))

                file.write("\n")

    def store_data_db(self, molecules):
        """
        Extracts melting and boiling point information, then stores it in
        database phase_properties collection.

        :param molecules: List of pymatgen.core.structure.Molecule objects.

        :return:
        """

        for molecule in molecules:
            adaptor = BabelMolAdaptor(molecule)
            # Use Canonical SMILES to ensure uniqueness
            smiles = adaptor.pybel_mol.write("can").strip()

            csids = self.get_chemspider_ids([molecule])[smiles]

            boiling_points = self.extract_boiling_point(csids)
            melting_points = self.extract_melting_point(csids)

            entry = {
                "molecule": molecule,
                "smiles": smiles,
                "boiling points": boiling_points,
                "melting_points": melting_points
            }

            self.collection.insert_one(entry)